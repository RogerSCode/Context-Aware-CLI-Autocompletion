
\section{The Programm}
For a practical application, we need a program that actually completes the commands.
Ideally, the autocompletion integrates seamlessly with the normal usage of the command line interface. For the sake of this thesis, we have to limit our program to the base functionality. Which means that advanced functions like the coloring of the prompt are not implemented. Our approach here is to build a wrapper around the terminal interface taking the user input, handing it to the terminal interpreter and adding a completion if ordered to do so. The output of the command is displayed as usual.


We chose to implement it on Linux for a bash shell. The reason for this is that aside from a pick one solution is that Linux among the major operating systems has the biggest focus on CLI usage and is even usable on Windows through the use of WSL.
 

Shell script is chosen as the  language because it is able to run on most UNIX-like systems.


Our script upon running presents us with a terminal prompt containing the current directory, which is also given to the autocompletion if along with the typed prompt by pressing the TAB key. The complete command can be executed like in a normal terminal by pressing the Enter key. 

Another function is that the program records the executed command in a history database, this is separate from the normal history. The idea behind it is that these commands along with the path they were executed in can be used to fine-tune the used model if so desired.


The autocompletion itself happens in a separate python file. The reason for this is that python offers better support for machine learning tasks compared to bash. This also offers the opportunity to use code from the model test with slight modifications.

In the python file, the specific model is chosen in a config file, which can be changed by the user.
The prompt template is modified by the directory and filenames is given to the model
Then the model uses it as context to predict  a completion for the command.
The predicted command is then returned.



\section{The Model}\raggedbottom
The Training of an LLM from scratch would be to cost/time intensive for this thesis so the use of a pretrained LLM is far more practical.

Now  we come to the question: Which model to choose and why? 
Since we want to complete cli commands we need a model that performs well on autocompletion tasks. So we preffer one whose architecture benefits such a task.

From a financial perspective it should be free to use which limits the use of nonfree APIs.

Since we want to use our autocompletion system on a 







We choose the specific models according to the categories of size speed and accuracy of output. while these factors can be influenced by finetuning and methods like Lora. We choose the strategie to pick the models with the best baseline.

For practical reasons we limit ourself to models that were publicated at the beginning of writing this thesis. So Models like LLama2 which was publicated during the writingprocces of this thesis were not considered.


\subsection{rejected models}


\subsubsection{BERT}
Bidirectional Encoder Representations from Transformers or short BERT was introduced  2018  in BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding \cite{devlin2019bert}. It was the first major Bidirectional model, which means it can use the context of right sided input in addition to left sided input. Unlike most previous models, which could only use left sided input.

 
 BERT's training data consists of two sources, the Bookscorpus and the English Wikipedia. The Bookscorpus is a dataset of textbooks containing approximately 800 million words, providing roughly one third of BERT's training data. The English Wikipedia dataset as its name implies contains texts from English Wikipedia articles limited to only the text passages. The lists, tables and headers have been removed.
Its size consists of approximately 2500 million word which makes it the majority of BERT's training data. \cite{devlin2019bert}


 Given the nature of an autocompletion task, this ability is not helpful. Since the model has to predict the entire right side of its input, there is no right side input it could use. So it would behave like a unidirectional model, losing its biggest architectural benefit.
 
However, it is to note that BERT's bidirectional encoding during training and the so encoded knowledge can benefit the predictions  for situations where only one directional encoding is possible.

The next point is that BERT is only able to use 512 tokens as context, which limits the size of its prompt length. While the template itself has a fixed number of tokens, the Path is of variable length. As well as the number of files.



The last issue with this model is the way its encoder handles out-of-vocabulary(OOV) tokens. Since Bert's encoder works with a fixed vocabulary it will not be able to process words that are not in its vocabulary. This poses a huge issue for named entities. This would include the names of programs, with whom most terminal commands start. As well as the names of files and directories which are given as context to the model. 

In our specific use case, this would mean that BERT could not use the given context and would be unable to complete some commands reasonably. 



These arguments lead to the conclusion that BERT is not suitable for this task. Therefore, we reject its use.





\subsubsection{GPT-3/GPT-4}

GPT-3 was first published in "Language Models are Few-Shot Learners" on May 28, 2020
by a group of researchers at OpenAI

While gpt based models as of now are considered to be the best LLMs. Their size and needed computational power to operate them make the impractibel for consumergrade computers. This can be cirkumvented by the use of the opeaiAPI but this is not free of charge and needs to sent data over the internet which prohibits its use with sensitive data and cannot be used on capsueld systems. 

\subsection{ LLama?} 
wile the LLama model is good at generating text its dreivate Alpaca is better at understanding the context of a prompt it 


\subsection{accepted Models}

\subsection{GPT-2}
 Generative Pre-trained Transformer 2 or short GPT-2 was introduced 2019 in the paper titled "Language Models are Unsupervised Multitask Learners"\cite{Radford2019LanguageMA}  . unlike BERT it is unidirectional
Its Trainingdata consists of Bookcorpus and webtext thus containing the same trainingsdata as BERT. Additionaly it contains code from github and text from reddit.

 autocompletion 
 encoder
 oov





\subsection{Alpaka} 
Stanfords Alpacka Model based on Metas LLama Model semes to be a good candidate.
We will use the Alpaca-7B version because it is the smalest. 


%\ifthenelse{\boolean{\biber}}{ % Beispiel um mit Biber zu zitieren (\citet und \citep)
%	\citet{Con97} hat ein Buch geschrieben. Es gibt auch andere Arbeiten \citep{PeHe97} die referenziert sind. In Abbildung \ref{fig_Gallien} ist ein Sachverhalt dargestellt.


%	1 Autor: \citet{Con97} \hspace*{1cm} \citep{Con97}\\
%	2 Autoren: \citet{IWNLP} \hspace*{1cm} \citep{IWNLP}\\
%	3 Autoren: \citet{liebeck-esau-conrad:2016:ArgMining2016} \hspace*{1cm} \citep{liebeck-esau-conrad:2016:ArgMining2016}

%	Online resource: \citet{ILSVRC2016}
%}{ %  Beispiel um klassisch zu zitieren (\cite)
%	\cite{Con97} hat ein Buch geschrieben. Es gibt auch andere Arbeiten \cite{PeHe97} die referenziert sind. In Abbildung \ref{fig_Gallien} ist ein Sachverhalt dargestellt.


%	1 Autor: \cite{Con97} \hspace*{1cm} \cite{Con97}\\
%	2 Autoren: \cite{IWNLP} \hspace*{1cm} \cite{IWNLP}\\
%	3 Autoren: \cite{liebeck-esau-conrad:2016:ArgMining2016} \hspace*{1cm} \cite{liebeck-esau-conrad:2016:ArgMining2016}

%	Online resource: \cite{ILSVRC2016}
%}

%\ifthenelse{\equal{\sprache}{deutsch}}{
%	\textbf{quotes}:\\
%	Ein Beispiel für deutsche Anführungszeichen \glqq quote\grqq.
%}{}

%\begin{figure}[htb]
%	\begin{center}
%		\includegraphics[width=175pt, angle=270]{bilder/Galia}
%		\caption{Gallien zur Zeit Caesars}\label{fig_Gallien}
%	\end{center}
%\end{figure}


%\begin{table}[htb]
%	\begin{center}
%		\begin{tabular}{|l|l|l|}
%			\hline
%			Jahr  & Erster Consul        & Zweiter Consul        \\
%			\hline \hline
%			1     & C. Caesar            & L. Aemilius Paullus   \\
%			2     & P. Vinicius          & P. Alfenus Varus      \\
%			3     & L. Aelius Lamia      & M. Servilius          \\
%			4     & Sex. Aelius Catus    & C. Sentius Saturninus \\
%			5     & L. Valerius Messalla & Cn. Cornelius Cinna   \\
%			suff. & C. Vibius Postumus   & C. Ateius Capito      \\
%			6     & M. Aemilius Lepidus  & L. Arruntius          \\
%			\hline
%		\end{tabular}
%		\caption{Römische Konsulen}\label{tab_Konsulen}
%	\end{center}
%\end{table}


\pagebreak
\section{tecnical background}
Since the training of LLMs would take to much time and be very expensive.Therfore not feasable. We just have to use pretrained models.


The models we use here are all transformerbased LLMs the reason for this is that the transformerarchitektur is the is the most powerful known architectur for language models and the defacto standart for all leading models






The final limitation given the task of autocomletion is that we need a model with. A word based model would not suffice because these models are not abel to autocomplete words just sentences. The ability to complete words is substancial for the task at hand.

\pagebreak



\section{setup}\raggedbottom

For reproducability we have to mention what kind of system and what kind of software
was used.





i used a Miniconda 3.1 enviroment

\begin{itemize}
\item \begin{verbatim}
transformers-4.30.2-pyhd8ed1ab_1.conda
\end{verbatim}

\item \begin{verbatim}
tokenizers-0.13.3-py38h7d131c9_0.conda
\end{verbatim}
  
\end{itemize}

pip
\begin{itemize}
\item \begin{verbatim}
numpy             1.25.0
\end{verbatim}

\item \begin{verbatim}
typing_extensions 4.7.0
\end{verbatim}
  
\end{itemize}


python version  3.11.3

system i testet it on 
p


\section{tests}
list of commands used
We used the following commands to autocomplete:
"sudo apt","sudo apt up","sudo apt in","ls","py","pyt","pyth","pytho","git","git i","git in","git ini","git co","git comm"

The reasons we chose these are to test four scenarios. First the relatievly context independent apt commands. Here we try to take a look how succesfull the autocompletion can be on a command that is not influenced by its context to have a comparrission with commands that are more influenced by their context.

Second the relatievly short "ls" command to test how a very short command is predicted.

Third python based commands that heavily relate to python files in the current directory. 


Last git based commands that are influenced 



It contains apt, python and git commands

reasons why i used these
tabelle fur die tests mit context

\section{prompt template}


The specific input to guide the behaviour of a machien learning model is caled "prompt". It is used as context by the model. The way the prompt is worded can heavily influence the behaviour of the model. Therefore we need a prompt that describes the tasks at hand. Which is to complete CLI-comands. There fore it is natural to simply tell the model what it is and what we want the model to do. 


Giving a linux system as context has the advantage to give the model context which completion would be plausible. 
But this limits its usage to system speciffic comands. To give an axemple of this the "ls" command would closer relate to  a linux terminal as the Windows/DOS equivalent "dir". This can easily be changed by replaceing the name of the system.






\begin{table}[htbp]
    \centering
    \caption{Prompt Variations}
    \begin{tabular}{|p{5cm}|p{8cm}|}
        \hline
        Premises & 
        \begin{itemize}
            \item You are an autocomplete function.
            \item This is a Linux terminal.
            \item This is a Linux terminal command.
            \item This is an autocomplete function.
        \end{itemize}
        \\
        \hline
        Order & 
        \begin{itemize}
            \item Autocomplete the following Linux terminal command and provide no further explanation for the command:
        \end{itemize}
        \\
        \hline
        File Contexts & 
        \begin{itemize}
            \item There are the following files in the current directory:
            \item Files:
            \item These files are in this directory:
        \end{itemize}
        \\
        \hline
    \end{tabular}
\end{table}


 

A number of prompt combinations have been tested and for simplicity we decided to choose the variation with the best outcome 


the "You are an autocomplete function. " and "This is an autocomplete function. " tend to provide significantly worse results than other premises. There are less likely to produce a terminal command, but a text about said command.

"This is a linux terminal command. " provides better output but tends to append an explanation of the command. "This is a linux terminal. " tends to provide the best solutions. 



Path and file in the current directory are not specified in the final prompt because these are defined by the context.


The file contexts show no significant differences, so "There are the following files in the current  directory: "is chosen to pick one for simplicity.



So the final prompt is: "This is a linux terminal. There are the following files in the current  directory: <files>,Path: <path>, Autocomplete the following linux terminal command and provide no further explanation for the command: <command>".


Now that we have the prompt template we can tend to the 


\pagebreak
\subsection{tests with gpt2}\raggedbottom

The unfinetuned gpt2 was chosen for its small size of round 550mb. Which makes it runnable on a low resource machine without any further processing. 

We used it with the Huggingface API since it is easy to use and the most popular API for such tasks. The "This is a linux terminal. There are the following files in the current  directory: <files>,Path: <path>, Autocomplete the following linux terminal command and provide no further explanation for the command: <command>" prompt as decided on in the previous section was used.


The model produced no valid commands while some of the git  completions resembled some git commands, none of them were valid.

While the speed was sufficient, its failure to produce valid commands suggests that

it is probably better to use a different model. 





I tested two scenarios with the gpt2 model first the apt based commands that worked insofar that it predicted the most commonly used apt commands update and install also with a lot of followup text, however most apt based commands are independent from their context insofar that they don't rely on the path they are executed in. It also has to be noted that the model produced more text appended to the command 


The git commands had way worse results. While trying to use the git  init command given the "git ini" was not able to predict the "t" of "init" correctly, and the "git c" wasn't able to predict anything near "git commit" not even  the "git comm" could predict "commit" most of the time even then not without a lot of unwanted text appended. The prepending of "Autocomplete the following terminal command:" seems to produce less unwanted text but still no usable output. 

\subsection{test with alpaca-7b}
While alpaca gives far better results, there are limits.


A test without any prefix showed only nonsensical results.

The apt commands often get completed into a text about apt based commands. While the ls command doesn't get interpreted as a command, presumably because it is short.

The python based commands mostly get completed into nonsensical text. Sometimes with python commands with more letters of the word "python" gets interpreted as a type of snake, which is not surprising considering the training data probably contains more text about snakes than the programming language. The git based commands again get completed into nonsensical text.


The added prefix  "This is a linux terminal. There are the following files in the current  directory:,Path:, Autocomplete the following linux terminal command and provide no further explanation for the command: <command>" shows an improvement, with apt and ls commands, with the notable outlier "py" who gets completed to the misspelled "pyhton" following a text about python.

The git based commands get completed in to nonfunctional git commands and text about these commands.


If we add a path and files in the current directory as context, we still cannot produce valid commands.

Noteworthy here is that sometimes the python commands dont get any completion at all.


This suggests that the base model is not able to do it in a sufficient way. Which makes methods like Lora not viable 
 to counter its slow speed and big size. Since it would lower its accuracy. 

Therefore fine-tuning the model is the next logical step.

\section{possible extensions}

It could be interesting to investigate if and how previous commands influence the outcome. Commands from the history could be added to the prompt. Although since this could be a high amount of tokens, the computational power needed therefore would be higher and the token limit of the model could be exceeded. Therefore, the commands need to be filtered. 


A different model could also be tested. While this was written,  LLama2  was released by Meta. It is a successor of LLama which alpaca is based on. It was not used solely for the reason that it came out late in the writing of this thesis.






\section{Sources}

paper für bert lama lama2 alpaca und wieso transformers die bestwe architectur sind einfügen